Instance: ""

# Site information that should match the CE Topology registration
Topology:
  Resource: RESOURCE_NAME
  ResourceGroup: RESOURCE_GROUP
  Sponsor: osg:100
  Contact: RESOURCE_CONTACT
  ContactEmail: support@example.edu
  City: City
  Country: US
  Latitude: 0.00
  Longitude: 0.00
  Production: true

RemoteCluster:
  # SSH host
  LoginHost: remote-ssh.login.org
  # SLATE secret with 'bosco.key' containing the SSH key to access LoginHost:
  PrivateKeySecret: lincolnb-bosco
  # condor, slurm, pbs, sge, or lsf
  Batch: slurm
  MemoryPerNode: 1024
  CoresPerNode: 4
  MaxWallTime: 1440
  # Name for the remote bosco installation dir
  BoscoDir: bosco
  # Absolute path to the local WN client installation. Should be one of:
  # - $HOME/bosco-osg-wn-client
  # - /cvmfs/oasis.opensciencegrid.org/osg-software/osg-wn-client/current/el7-x86_64/
  #   (replacing "el7" with the remote OS major version)
  GridDir: $HOME/bosco-osg-wn-client
  # Worker node scratch space for payload jobs
  # 1. For non-HTCondor batch systems, use of environment vars is supported
  # 2. For HTCondor batch systems, only "$HOME" is accepted. For an
  #    HTCondor site a directory specified in MOUNT_UNDER_SCRATCH in
  #    their HTCondor configuration, or ask the Factory to specify
  #    'work_dir="Condor"' in the appropriate entries
  WorkerNodeTemp: /tmp
  # <IP OR FQDN>:<PORT> for the site's local squid server, or 'null' if no site Squid
  Squid: null
  # Control the value of the SSH BatchMode option used by the CE for
  # communication with the remote cluster
  SSHBatchMode: True

Networking:
  ServiceType: "LoadBalancer"
  # The hostname that the CE should use. 
  # Appropriate A and PTR DNS records must exist.
  Hostname: ""
  # The preferred IP address which should be requested from the LoadBalancer. 
  # This may be left as null to express no preference. 
  # Setting this may be useful when redeploying a CE in order to try to get
  # back the same IP address that was used previously. 
  RequestIP: null

# VOMS FQAN to remote user mapping
# This list controls the VOs accepted by the CE and the users they are
# mapped to on the remote site.
#
# To disallow VOs, remove the relevant item from the list.
# To change the remote user for a given VO, change the value (e.g. osg01)
# To add custom VOMS FQAN mappings, add a new item to the list.
# VOMS FQANs can include "*" wildcards.
VoRemoteUserMapping:
  # https://github.com/opensciencegrid/topology/blob/master/virtual-organizations/OSG.yaml
  - "/osg/Role=NULL/Capability=NULL": osg01
  # https://github.com/opensciencegrid/topology/blob/master/virtual-organizations/GLOW.yaml
  - "/GLOW/Role=htpc/Capability=NULL": osg02
  # https://github.com/opensciencegrid/topology/blob/master/virtual-organizations/HCC.yaml
  - "/hcc/Role=NULL/Capability=NULL": osg03
  # https://github.com/opensciencegrid/topology/blob/master/virtual-organizations/CMS.yaml
  - "/cms/*": osg04
  # https://github.com/opensciencegrid/topology/blob/master/virtual-organizations/Fermilab.yaml
  - "/fermilab/*": osg05
  # osg06 reserved for JLAB
  # LIGO-Virgo collaboration
  # https://github.com/opensciencegrid/topology/blob/master/virtual-organizations/LIGO.yaml
  - "/osg/ligo/Role=NULL/Capability=NULL": osg07
  - "/virgo/ligo/Role=NULL/Capability=NULL": osg07
  # Brookhaven National Lab VOs
  # https://github.com/opensciencegrid/topology/blob/master/virtual-organizations/sPHENIX.yaml
  - "/sdcc/Role=NULL/Capability=NULL": osg08
  - "/sphenix/Role=NULL/Capability=NULL": osg08
  # https://github.com/opensciencegrid/topology/blob/master/virtual-organizations/ATLAS.yaml
  - "/atlas/*": osg09
  # https://github.com/opensciencegrid/topology/blob/master/virtual-organizations/Gluex.yaml
  - "/Gluex/Role=NULL/Capability=NULL": osg10
  # https://github.com/opensciencegrid/topology/blob/master/virtual-organizations/DUNE.yaml
  - "/dune/Role=pilot/Capability=NULL": osg11
  # https://github.com/opensciencegrid/topology/blob/master/virtual-organizations/IceCube.yaml
  - "/icecube/Role=pilot/Capability=NULL": osg12
  # https://github.com/opensciencegrid/topology/blob/master/virtual-organizations/XENON.yaml
  - "/xenon.biggrid.nl/Role=NULL/Capability=NULL": osg13

##########################
# OPTIONAL CONFIGURATION #
##########################

# DN to remote user mapping
# For example, you may add your personal certificate's subject DN so
# that you can submit jobs to this CE
#DnRemoteUserMapping:
#  - "/DC=foo/DC=bar/OU=Organic Units/OU=Users/CN=YourUserName": osg01

# Specify additional HTCondor-CE configuration
# HTCondorCeConfig: |+
#   ALL_DEBUG = D_ALWAYS:2 D_CAT

# Enable persistence to HostedCE files by creating corresponding SLATE Volumes
# SLATE Creates a PVC in Kubernetes which can be reclaimed on restart
# The value for each volume should correspond to the volume name within SLATE
Persistence:
  # /var/log/condor-ce
  LogVolume: null 
  # /var/lib/condor-ce
  LibCondorCeVolume: null

# Options to allow override of the bosco directory from arbitrary git repos
# Bosco override dirs are expected in the following location in the git repo:
#   <RESOURCE NAME>/bosco_override/
BoscoOverrides:
  Enabled: false
  GitEndpoint: https://github.com/slateci/bosco-override-template
  # If GitEndpoint requires authentication, create a SLATE secret with
  # 'git.key' containing the private SSH key that can access
  # it. Specify the name of the secret in GitKeySecret:
  GitKeySecret: null
  # Bosco tarball URL to use for installation on the remote login host
  # instead of the default determined by the Hosted CE
  TarballURL: null

# Enable a logging sidecar
HTTPLogger:
  Enabled: true
  # If you want to insert a password instead of using a randomly generated one,
  # point Secret to a K8S/SLATE secret below.
  # Secret: my-secret

# If a specific node is desired for scheduling
# set this to the hostname of the desired node
NodeSelection: null

HostCredentials:
  # Suitable values are "certmanager", "external", and "http"
  #  CertManager -> Create a CertManager certificate object. See also LetsEncryptStaging option.
  #  External -> K8S cluster operator will provide a HostCertSecret and
  #              HostKeySecret corresponding to an IGTF certificate
  #  HTTP     -> Pod will start an nginx service and attempt to issue a Let's Encrypt cert
  Provider: HTTP
  # If set to 'true', use the Let's Encrypt staging server. This is
  # useful for avoiding Let's Encrypt rate limits when first setting
  # up a CE. NOT SUITABLE FOR PRODUCTION USE.
  LetsEncryptStaging: true
  # Create a secret via CertManager. Only applies if Provider is set to certmanager
  CertManager:
    ClusterIssuer: false # If true, add "kind: ClusterIssuer to secret" otherwise assume Issuer
  # Create a secret external to SLATE and reference it here
  External:
    HostCertSecret: null
    HostKeySecret: null

# Choose which tag to use for the specified containers
ContainerTags:
  HostedCE: stable

# FOR DEVELOPMENT PURPOSES ONLY!
# Setting 'Enabled: true' below does the following:
# - Configures the CE as an ITB host
# - Generates a test CA and self-signed host cert/key pair
Developer:
  Enabled: false

### SLATE-START ###
SLATE:
  Instance:
    ID: "untagged"
### SLATE-END ###
